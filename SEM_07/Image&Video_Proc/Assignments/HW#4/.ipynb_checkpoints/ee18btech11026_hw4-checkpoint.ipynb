{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import Matrix, init_printing\n",
    "random.seed(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP :\n",
    "    def __init__(self,X_train,Y_train,hidden_nodes = 2):\n",
    "        \n",
    "        \n",
    "        self.X = X_train\n",
    "        self.Y = Y_train\n",
    "        din,n = self.X.shape  ### din = 2 in this case ,n --> no. ofsamples\n",
    "        self.m = hidden_nodes\n",
    "        \n",
    "        #### H -> hidden nodes output\n",
    "        #### W_h -> weights between input and hidden layer\n",
    "        #### W_o -> weights between hidden and output layer\n",
    "        \n",
    "        self.H = np.ones((self.m +1,n))## initialising random weights\n",
    "        self.W_h = np.random.random((din,self.H.shape[0]))\n",
    "        self.W_o = np.random.random((self.H.shape[0],self.Y.shape[0]))\n",
    "    \n",
    "    def forward_pass(self,X):\n",
    "        H = self.H\n",
    "        W_h = self.W_h\n",
    "        W_o = self.W_o\n",
    "\n",
    "        def sigmoid (w,x) :\n",
    "            act = np.transpose(w)@x\n",
    "            return 1/(1+np.exp(-1*act))\n",
    "        \n",
    "        ######################################\n",
    "    \n",
    "        H = sigmoid(W_h,X)\n",
    "        H[0,:] = np.ones(H[0,:].shape)  ### resetting bias to 1\n",
    "        Y_pred = sigmoid(W_o,H) \n",
    "        \n",
    "        return H,Y_pred\n",
    "    \n",
    "    def back_prop(self,X,Y):\n",
    "        H= self.H\n",
    "        Y_pred = self.Y_pred\n",
    "        W_o  = self.W_o\n",
    "        W_h = self.W_h\n",
    "        \n",
    "        def output_loss(y,y_hat):\n",
    "            return (-1*(y - y_hat))\n",
    "        \n",
    "        def sig_loss(y_hat):\n",
    "            return np.multiply((1 - y_hat) , (y_hat))\n",
    "        \n",
    "        ########################################\n",
    "        \n",
    "        #### Back prop : \n",
    "        W_o_grad = W_o.copy()\n",
    "        W_h_grad = W_h.copy()\n",
    "        W_o_new = W_o.copy()\n",
    "        W_h_new = W_h.copy()\n",
    "        lr = self.lr\n",
    "            \n",
    "        #### Updating output weights : \n",
    "        for i in range(W_o_grad.shape[0]):\n",
    "            for j in range(W_o_grad.shape[1]):\n",
    "                W_o_grad[i][j] = np.mean( loss(Y[j],Y_pred[j]) * sig_loss(Y_pred[j]) * H[i] )\n",
    "                W_o_new[i][j] = W_o[i][j] - (lr* W_o_grad[i][j] ) \n",
    "                \n",
    "        ##### Updating input weights:\n",
    "        k = 0   #### TODO for multi dim op\n",
    "        for i in range(W_h_grad.shape[0]):\n",
    "            for j in range(W_h_grad.shape[1]):\n",
    "                W_h_grad[i][j] = np.mean( loss(Y[k],Y_pred[k]) * sig_loss(Y_pred[k]) * W_o[j][k] * sig_loss(H[j]) * X[i] )\n",
    "                W_h_new[i][j] = W_h[i][j] - ( lr*W_h_grad[i][j] )\n",
    "                \n",
    "                \n",
    "        def run_epochs(self,X,Y,epochs, bs, lr, train_val_ratio = 0.8, plot = False):\n",
    "            self.lr = lr\n",
    "            epoch_error = np.zeros(epochs)\n",
    "            X_train, X_val, Y_train, Y_val = split_train_val(X_xor,Y_xor, train_val_ratio)\n",
    "            \n",
    "            for e in range(epochs):\n",
    "                for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10554342 0.10126975 0.32440318]\n",
      " [0.98010135 0.72674682 0.66260076]\n",
      " [0.83768615 0.0427684  0.72459018]\n",
      " [0.33413959 0.09768944 0.02014227]\n",
      " [0.06023316 0.78103094 0.72504076]]\n",
      "[0, 2, 1]\n",
      "[[0.10554342 0.32440318 0.10126975]\n",
      " [0.98010135 0.66260076 0.72674682]\n",
      " [0.83768615 0.72459018 0.0427684 ]\n",
      " [0.33413959 0.02014227 0.09768944]\n",
      " [0.06023316 0.72504076 0.78103094]]\n"
     ]
    }
   ],
   "source": [
    "mat = np.random.random((5,3))\n",
    "print(mat)\n",
    "\n",
    "m = mat.shape[1]\n",
    "permutation = list(np.random.permutation(m))\n",
    "\n",
    "\n",
    "shuffled_matrix = mat[:, permutation]\n",
    "print(permutation)\n",
    "print(shuffled_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_batches(X,Y,bs):\n",
    "    '''\n",
    "    returns a list of batches\n",
    "    '''\n",
    "    \n",
    "    samples_no = X.shape[1]\n",
    "    \n",
    "    idx_permute = list(np.random.permutaion(m))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if axis == 0: # by column\n",
    "        m = matrix.shape[1]\n",
    "        permutation = list(np.random.permutation(m))\n",
    "        shuffled_matrix = matrix[:, permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95257413 0.95257413]\n",
      " [0.95257413 0.95257413]\n",
      " [0.95257413 0.95257413]]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid (w,x) :\n",
    "    act = np.transpose(w)@x\n",
    "    return 1/(1+np.exp(-1*act))\n",
    "\n",
    "print(sigmoid(np.ones( (3,3) ), np.ones((3,2) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(np.ones((3,1) ), np.ones((3,1) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 5.]\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((3,3))\n",
    "a [0][2] = 5\n",
    "\n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.07482073e-03  9.14785553e-01 -3.77992787e-02 -2.37394224e-02\n",
      "   9.56839510e-01  9.34459740e-01  1.54931355e-02  5.15887513e-02\n",
      "  -1.62586308e-02  9.95145676e-01]\n",
      " [-2.07472679e-02  9.96906517e-01 -1.24017265e-02  1.03070640e+00\n",
      "   6.33461290e-02  7.01386312e-03  9.96789127e-01  9.81886415e-01\n",
      "  -5.70949376e-03 -7.60545299e-04]]\n",
      "[[0 0 0 1 1 1 1 1 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####  Creating a dataset\n",
    "\n",
    "\n",
    "\n",
    "def create_XOR_data(data_size,var):\n",
    "    \n",
    "    A = np.random.binomial(size = data_size, n=1, p= 0.5)\n",
    "    B = np.random.binomial(size = data_size, n=1, p= 0.5)\n",
    "    X = np.array((A,B))\n",
    "    Y = np.logical_xor(X[0],X[1]) + 0\n",
    "    \n",
    "    \n",
    "    color = ['black'*(1-i) + 'cyan'*(i) for i in (Y) ]\n",
    "    \n",
    "    X_noise= X + np.random.normal(0, var, X.shape)\n",
    "    Y_final = Y.reshape((1,Y.shape[0]))\n",
    "    \n",
    "    ### plotting : \n",
    "    plt.scatter(X_noise[0],X_noise[1],color = color)\n",
    "    plt.figure()\n",
    "    \n",
    "    return X_noise,Y_final\n",
    "\n",
    "X_xor, Y_xor = create_XOR_data(10, 0.05)\n",
    "print(X_xor)\n",
    "\n",
    "print(Y_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10)\n",
      "(2, 8)\n",
      "(2, 2)\n",
      "[[ 3.07482073e-03  9.14785553e-01 -3.77992787e-02 -2.37394224e-02\n",
      "   9.56839510e-01  9.34459740e-01  1.54931355e-02  5.15887513e-02\n",
      "  -1.62586308e-02  9.95145676e-01]\n",
      " [-2.07472679e-02  9.96906517e-01 -1.24017265e-02  1.03070640e+00\n",
      "   6.33461290e-02  7.01386312e-03  9.96789127e-01  9.81886415e-01\n",
      "  -5.70949376e-03 -7.60545299e-04]]\n",
      "[[ 0.00307482  0.91478555 -0.03779928 -0.02373942  0.95683951  0.93445974\n",
      "   0.01549314  0.05158875]\n",
      " [-0.02074727  0.99690652 -0.01240173  1.0307064   0.06334613  0.00701386\n",
      "   0.99678913  0.98188642]]\n",
      "[[-1.62586308e-02  9.95145676e-01]\n",
      " [-5.70949376e-03 -7.60545299e-04]]\n",
      "--------------\n",
      "[[0 0 0 1 1 1 1 1 0 1]]\n",
      "[[0 0 0 1 1 1 1 1]]\n",
      "[[0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_xor.shape)\n",
    "\n",
    "\n",
    "\n",
    "def split_train_val(X,Y, train_percent):\n",
    "    n = X.shape[1]\n",
    "    X_train,X_val = X[:,:int(train_percent*n)], X[:,int(train_percent*n) :]\n",
    "    Y_train,Y_val = Y[:,:int(train_percent*n)], Y[:,int(train_percent*n) :]\n",
    "    return X_train, X_val , Y_train, Y_val\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = split_train_val(X_xor,Y_xor, 0.8)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "\n",
    "print(X_xor)\n",
    "print(X_train)\n",
    "print(X_val)\n",
    "print('--------------')\n",
    "print(Y_xor)\n",
    "print(Y_train)\n",
    "print(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
